\href{src.zip}{Исходный код к теме}
\section{Дискретное распределение}
Бросим n раз монету, пусть m раз выпал орёл.
f = m/n -  частота выпадения орла.
Это - случайная величина, 
Исследуем её при помощи компьютерной симуляции. 
Для этого нам понадобится модуль random, он содержит 
генераторы псевдослучайных значений.
Например
\begin{lstlisting}[language=Python]
<<prob.py>>=
from random import choices
res = choices([0, 1], k = 10)
print(res)
@
\end{lstlisting}
res будет содержать список из k нулей и единиц,
с генерированных псевдослучайно.
\begin{lstlisting}[language=Python]
<<>>=
[1, 0, 1, 1, 1, 0, 1, 0, 1, 0]
@
\end{lstlisting}
Единицу будем считать выпадением орла на монете,
а 0 - решки.
\begin{lstlisting}[language=Python]
<<prob.py>>=
def flips(nFlips):
	'''nFlips число бросаний монеты,
	возвращает h - частоту выпадения орла.'''
	res = choices([0, 1], k = nFlips)
	h = sum(res)/nFlips 
	return  h
@
\end{lstlisting}
Для начала будем бросать по 10 раз и записывать частоту.
Проведём это опыт 8 раз
\begin{lstlisting}[language=Python]
<<prob.py>>=
res = [flips(10) for k in range(8)]
print(res)
@
\end{lstlisting}
получили
\begin{lstlisting}[language=Python]
<<>>=
[0.5, 0.4, 0.6, 0.5, 0.7, 0.3, 0.8, 0.6].
@
\end{lstlisting}

Мы видим что частота имеет сильно различающиеся значения.
Разница между самым большим 0.8 и самым маленьким 0.3, 
равна 0.5. 

Будем бросать монету 1000 раз и записывать частоту.
\begin{lstlisting}[language=Python]
<<prob.py>>=
res = [flips(1000) for k in range(8)]
print(res)
@
\end{lstlisting}
получили
\begin{lstlisting}[language=Python]
<<>>=
[0.515, 0.484, 0.522, 0.498, 0.498, 0.513, 0.511, 0.486]
@
\end{lstlisting}
Значения близки к 0.5, их разброс стал гораздо меньше.
Самая большая разница равна 0.038.
Мы получили, что при увеличении числа бросаний,
частота стремиться к некоторому пределу, 
назовём его  вероятностью выпадения орла.


\section{Аксиомы}
Рассмотрим аксиомы теории вероятностей, сформулированные
Колмогоровым.

$\Omega$ - множество элементарных событий, будем называть
пространством элементарных событий. $F$ - множество
всех подмножеств, его элементы будем называть случайными 
событиями. 
\begin{enumerate}
\item $F$ - является алгеброй множеств.
\item Каждому множество $A$ из $F$ сопоставлено 
неотрицательное число $P(A)$. Это число называется
вероятностью события $A$.
\item $P(\Omega) = 1.$
\item Если $A$ и $B$ не пересекаются, то
$$P(A + B) = P(A) + P(B).$$ 
\end{enumerate}
Совокупность объектов $(\Omega, F, P)$ удовлетворяющих этим
аксиомам назовём полем вероятностей.

\section{Связь с опытом}
Эксперименты со случайным исходом являются интерпретацией
теории вероятностей.
Так выпадение орла или решки в опыте с монетой - это элементарное событие. 
При бросании кубика элементарными событием будет, например,
выпадение 1. 
Событие выпадение чётного числа на кубике - это 
подмножество [2, 4, 6]. 

На событиях мы можем задать операции 
сложения(\(+, \cup\)) и умножения (\(*,\cap\)).
\begin{itemize}
\item \(A \cup B = X\) событие $X$ заключается в том, что 
произошло по крайней мере одно из событий \(A\) или \(B\). 
\item Если $A\cup B=\emptyset$, будем говорить что события 
несовместные. 
\item Если $A\cup B \cup C =X$, будем говорить
событие $X$ состоит в совместном наблюдении событий 
$A,B,C$.
\item Если $U=[A_1, A_2,... A_n]$
система не пересекающихся множеств, разлагающая
$\Omega$, т.е.
$$A_1 + A_2 .. +A_n = \Omega$$,
то будем говорить, что испытание $U$ устанавливает
какое из событий $A_1, A_2, .. A_n$ произошло.
\end{itemize}

\section{Условная вероятность}
Если $P(a)>0$, то 
\begin{equation}\label{condDist}
P(B\mid A)= \frac{P(AB)}{P(A)}
\end{equation}
назовём условной вероятностью события $B$ при условии
$A$. Из (\ref{condDist}) следует, что
\begin{equation}\label{jointDist}
P(AB)=P(A)P(B\mid A).
\end{equation}
Можно проверить, что при фиксированном событии $A$, 
условные вероятности событий при условии $A$ удовлетворяют
аксиомам поля вероятностей. 
$$
P(C+B \mid A)=P(C\mid A) + P(B\mid A)
$$
$$
P(B\mid A) \ge 0
$$
$$
P(\Omega\mid A) = 1
$$ 
Т.е. условная вероятность
задаёт новое поле вероятностей.

Из (\ref{jointDist}) и аналогичной формулы 
\begin{equation}
P(AB)=P(B)P(A\mid B)
\end{equation}
следует, получаем 
\begin{equation}\label{bayesH}
P(A\mid B) = \frac{P(A)P(B\mid A)}{P(B)}.
\end{equation}

\begin{theorem}(о полной вероятности).
Пусть $A_1+A_2+A_3..+A_n=\Omega$\  и B произвольное событие.
Тогда
\begin{equation}\label{total}
P(B) = P(A_1)P(B\mid A_1) + P(A_2)P(B\mid A_2) +... + P(A_n)P(B\mid A_n).
\end{equation} 
\end{theorem}
\begin{proof}
Поскольку
$$
B = BA_1 + BA_2 + ... +BA_n,
$$
то, согласно 4 аксиоме, получаем
$$
P(B)=P(BA_1)+P(BA_2) + ... +P(PA_n).
$$
Согласно (\ref{jointDist}) при этом имеем равенство
$$
P(BA_i) = P(A_i)P(B\mid A_i)
$$
\end{proof}
\begin{theorem}
(Байеса).
Пусть $A_1+A_2+...+A_n=\Omega$\  и $B$ \ произвольное 
событие. Тогда
\begin{equation}\label{bayes}
P(A_i \mid B) = \frac{P(A_i) P(B \mid A_i)}{P(A_1)P(B \mid A_1) + P(A_2)P(B \mid A_2) + .. +P(A_n) P(B\mid A_n)}.
\end{equation}
\end{theorem}
\begin{proof}
В формулу (\ref{bayesH}), подставим  (\ref{total})
\end{proof}

События $A_1, A_2,..A_n$ часто называют гипотезами, и 
говрят, что формула (\ref{bayes}) вероятность $P(A_i \mid b)$\ 
гипотезы $A_i$ \ после наступлении события $B$. $P(A_i)$ \ даёт
априорную вероятность.
 
\section{Независимость}
Пусть $V=(A_1, A_2, ...A_n)$ испытание, 
$W=(B_1, B_2, ..,B_m)$ другое испытание,
то эти испытания будем называть независимыми, 
если для любого $i, j$ 
имеет место равенство
$$
P(A_i B_j) = P(A_i) P(B_j).
$$
\section{Случайная величина}
Пусть $U$ испытание, разлагающее основное множество $\Omega$,
$$
A_1+A_2+..A_n=\Omega,
$$
$X = X(\omega)$ действительная функция элементарного
события $\omega$, которая на каждом множестве $A_i$,
принимает значение $x_i$, будем её называть случайной величиной.
\begin{equation}
E(X)=\sum_i^n x_i P(A_i)=\sum X(w_i)P(w_i)
\end{equation}
будем называть математическим ожиданием.

Свойства математического ожидания
\begin{equation}\label{constE}
E(cX)=cE(x)
\end{equation}
\begin{equation}
E(X + Y) = E(X) + E(Y)
\end{equation}
Если $X, Y$ независимые случайные величины, то
\begin{equation}
E(XY)=E(X)E(Y)
\end{equation}
Докажем свойство (\ref{constE})
$$
E(cX)=\sum cx_iP(A_i)=c\sum cx_iP(A_i)=cE(X).
$$
Докажем оставшиеся свойства
$$
E(X+Y)=\sum (X(w_i)+Y(w_i)) P(w_i)=\sum X(w_i)P(w_i) + \sum Y(w_i)P(w_i)=E(X)+E(Y)
$$
$$
E(XY)=\sum x_{j}y_{i}P(X=x_{j} and Y=y_{i})=\sum x_{j} y_{i}P(X=x_{j})P(Y=y_{i})=\sum x_{j}P(X=x_{j}) \sum y_i P(Y=y_i) = E(X)E(Y)
$$

